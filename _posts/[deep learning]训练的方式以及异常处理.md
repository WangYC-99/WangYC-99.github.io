# [Deep Learning]训练的方式以及异常处理

> by WangYC_99
>
> @home Feb. 21st 2022

## 1. 监督学习 无监督学习 半监督学习

**监督学习：**数据全部打标签，训练过程只是对模型进行优化，有明确的输出预期值。

**无监督学习：**没有数据打标签，没有固定的输出预期，训练的过程同时也是在打标签。

**半监督学习：**一部分数据打标签，另一部分不打标签，训练的过程是在给一开始没有标签的数据打标签的过程。

参考：<a href = "https://blog.csdn.net/u013250861/article/details/111598498">详细的半监督学习的方法博客</a>

## 2. 数据集划分方法

### 2.1 训练集、测试集、验证集

**训练集**：用于训练的数据，所有属性网络可知，往往需要经过预处理。

**测试集：**用于测试用上述训练集的数据训练的模型的泛化能力，属性网络不可知，不经过预处理。

**验证集：**用于在同一个场景中选择不同网络或者同一个网络选择不同的参数的时候来给出一个准确的评价。

### 2.2 三者的运用场景：

如果场景十分单一，并且实验成本很低，同时你也不嫌弃如果模型表现不好你要重新训练麻烦，那你直接用全部数据当作是训练集就可以。

一般情况下是要将数据集划分为训练集和测试集。

如果你有多个模型或者你有一个模型的不同参数，那么就要利用验证集，这其中涉及到一个“信息泄露”的概念，具体可以参照博客<a href="https://zhuanlan.zhihu.com/p/48976706">信息泄露</a>。

### 2.3 划分方法

在吴恩达老师视频中介绍的经验就是：

1. 当数据量不大的时候，也就是万级别或者以下的时候，则划为6:2:2，这样划分就可以了。
2. 当数据量特别大的时候，大数据，还按6:2:2划分验证集和测试集的话，可能得到的验证集和测试集数量非常大，我们肯定想着拿去训练的样本越多越好，这个时候按98:1:1就好了，举得例子就是100万条样本，1万条做验证，1万条做测试，网络就能够很好的工作。

## 3. 训练的异常情况：过拟合以及欠拟合

### 3.1 概念

1. **训练过程loss的变化规律**：初期训练集和测试集的loss都在下降，超过一个点以后训练集的loss保持下降，但是测试机的loss反而会上升。
2. **欠拟合：**两个loss都还在下降的阶段叫做欠拟合。
3. **过拟合：**训练集的loss下降而测试集的loss上升的阶段叫做过拟合。

### 3.2 解决方法

#### 3.2.1 欠拟合解决方啊：

欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。但是如果真的还是存在的话，可以通过**增加网络复杂度**或者在模型中**增加特征**，这些都是很好解决欠拟合的方法。

#### 3.2.2 过拟合解决方案：

1. 获取和使用更多的数据（数据集增强）——解决过拟合的根本性方法
2. 采用合适的模型（控制模型的复杂度）

3. 降低特征的数量
4. 正则化
5. Dropout
6. Early stopping

> 参考：https://zhuanlan.zhihu.com/p/72038532